{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition Challenge - Parth S. Patel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem:\n",
    "We will try to build a classification model that will run through multiple 2d pics of famous celebreties and predict name based on image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python 3.5\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.tensorboard import Tensorboard\n",
    "from model import Model\n",
    "from utils.augment import Augment\n",
    "from train import train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "Fetch the data and split into images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = fetch_lfw_people(data_home=None,\n",
    "                           resize=1.0,\n",
    "                           color=True,\n",
    "                           download_if_missing=True,\n",
    "                           min_faces_per_person=20)\n",
    "\n",
    "images = dataset.images\n",
    "labels = dataset.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One Hot Encode the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_encoded = np.zeros((len(labels), len(set(labels))))\n",
    "labels_encoded[np.arange(len(labels)), labels] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Data Shape: (3023, 125, 94, 3)\n",
      "> Label Shape: (3023,)\n",
      "> Number of Classes: 62\n",
      "> People: {'Junichiro Koizumi', 'Saddam Hussein', 'Alejandro Toledo', 'George W Bush', 'John Ashcroft', 'Tom Daschle', 'David Beckham', 'Jose Maria Aznar', 'Bill Clinton', 'Lleyton Hewitt', 'Vicente Fox', 'Amelie Mauresmo', 'Mahmoud Abbas', 'Donald Rumsfeld', 'Serena Williams', 'Angelina Jolie', 'George Robertson', 'Ariel Sharon', 'Guillermo Coria', 'Jack Straw', 'Jennifer Lopez', 'Megawati Sukarnoputri', 'Alvaro Uribe', 'Roh Moo-hyun', 'Jiang Zemin', 'Arnold Schwarzenegger', 'Nestor Kirchner', 'Andre Agassi', 'Pete Sampras', 'Hamid Karzai', 'Tom Ridge', 'Lindsay Davenport', 'Tiger Woods', 'Jean Chretien', 'Atal Bihari Vajpayee', 'Hans Blix', 'Silvio Berlusconi', 'Igor Ivanov', 'Hugo Chavez', 'Laura Bush', 'Gerhard Schroeder', 'Recep Tayyip Erdogan', 'Carlos Menem', 'Vladimir Putin', 'Jennifer Capriati', 'John Negroponte', 'Michael Bloomberg', 'Gray Davis', 'Jennifer Aniston', 'Naomi Watts', 'Kofi Annan', 'Jeremy Greenstock', 'Paul Bremer', 'Ricardo Lagos', 'Winona Ryder', 'Colin Powell', 'Jacques Chirac', 'Luiz Inacio Lula da Silva', 'Gloria Macapagal Arroyo', 'Juan Carlos Ferrero', 'Tony Blair', 'Rudolph Giuliani'}\n",
      "> Classes: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61}\n"
     ]
    }
   ],
   "source": [
    "print('> Data Shape: {}'.format(images.shape))\n",
    "print('> Label Shape: {}'.format(labels.shape))\n",
    "print('> Number of Classes: {}'.format(len(set(dataset.target_names))))\n",
    "print('> People: {}'.format(set(dataset.target_names)))\n",
    "print('> Classes: {}'.format(set(labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation\n",
    "Augment the data through:\n",
    "* random cropping of the image from 125x94 to 63x63 pixels\n",
    "* randomly modifying the hue, contrast, brightness\n",
    "* randomly flip images horizontally\n",
    "\n",
    "*Warning: Augmentation takes a long time.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crop the images twice to double the data size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = Augment()\n",
    "croped = []\n",
    "for _ in range(2):\n",
    "    croped.append(aug.randomCropAll(images, 63, 63))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crop, modify hue, contrast, brightness, and flip the images three times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Augmented images with ['flip_h', 'brightness', 'hue']\n"
     ]
    }
   ],
   "source": [
    "a1 = aug.augment(images=images,\n",
    "                 operations=['flip_h', 'brightness', 'hue'],\n",
    "                 width=63,\n",
    "                 height=63)\n",
    "\n",
    "a2 = aug.augment(images=images,\n",
    "                 operations=['flip_h', 'hue'],\n",
    "                 width=63,\n",
    "                 height=63)\n",
    "\n",
    "a3 = aug.augment(images=images,\n",
    "                 operations=['flip_h', 'contrast', 'hue'],\n",
    "                 width=63,\n",
    "                 height=63)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the augmented images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_augments = (croped[0], croped[1], a1, a2, a3)\n",
    "\n",
    "images_selected = np.concatenate(combined_augments, axis=0)\n",
    "labels_selected = np.concatenate([labels_encoded for _ in range(len(combined_augments))], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure the images and labels are numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if type(images_selected).__module__ is not np.__name__:\n",
    "    print('> Converting images to a numpy array')\n",
    "    images_selected = np.array(images_selected)\n",
    "\n",
    "if type(labels_selected).__module__ is not np.__name__:\n",
    "    print('> Converting labels to a numpy array')\n",
    "    labels_selected = np.array(labels_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augmented Data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('> Data Shape: {}'.format(images.shape))\n",
    "print('> Label Shape: {}'.format(labels.shape))\n",
    "print('> Number of Classes: {}'.format(len(set(dataset.target_names))))\n",
    "print('> People: {}'.format(set(dataset.target_names)))\n",
    "print('> Classes: {}'.format(set(labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split Data into training, test, and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(images_selected, labels_selected, test_size=0.30)\n",
    "X_train, X_val, y_train, y_val = train_test_split(images_selected, labels_selected, test_size=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorboard parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_directory = r'./tmp/tensorboard/015'\n",
    "tensorboard_paths = [r'C:\\Users\\parth\\Documents\\GitHub\\Facial-Recognition\\tmp\\tensorboard\\015']\n",
    "tensorboard_names = ['model']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorboard command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensorboard.make(paths=tensorboard_paths,\n",
    "                 names=tensorboard_names,\n",
    "                 host='127.0.0.1',\n",
    "                 _print=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tunable Training Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conv2d Params\n",
    "* filters : Integer, dimensionality of the output space (ie. the number of filters in the convolution)\n",
    "* kernel_size : An integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution window.  Can be a single integer to specify the same value for all spatial dimensions\n",
    "* strides : An integer or tuple/list of 2 integers, specifying the strides of the convolution along the height and width.  Can be a single integer to specify the same value for all spatial dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2d_specifications = [[{'filters': 64, 'kernel_size': [3, 3], 'strides': (1, 1)}],\n",
    "                         [{'filters': 64, 'kernel_size': [5, 5], 'strides': (1, 1)}],\n",
    "                         [{'filters': 64, 'kernel_size': [7, 7], 'strides': (1, 1)}]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Max Pool Params\n",
    "* pool_size : An integer or tuple/list of 2 integers: (pool_height, pool_width) specifying the size of the pooling window.  Can be a single integer to specify the same value for all spatial dimensions\n",
    "* strides : n integer or tuple/list of 2 integers, specifying the strides of the pooling operation.  Can be a single integer to specify the same value for all spatial dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pool_specifications = [[{'use': True, 'pool_size': [3, 3], 'strides': [1, 1]}],\n",
    "                           [{'use': True, 'pool_size': [3, 3], 'strides': [1, 1]}],\n",
    "                           [{'use': True, 'pool_size': [3, 3], 'strides': [1, 1]}]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fully Connected & Dense Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dense = 2\n",
    "fc_parameters = [{'units': 62}, {'units': 62}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropout Params\n",
    "* use : to use dropout in this layer\n",
    "* rate : dropout rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_parameters = [{'use': True, 'rate': 0.5},\n",
    "                      {'use': True, 'rate': 0.5}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001  # A const. learning rate is not defined in the model, instead the learning rate changes as the model trains.\n",
    "epochs = 5000\n",
    "use_batch_norm = True\n",
    "use_dropout = True\n",
    "batch_size = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('> Data Shape: {}'.format(images_selected.shape))\n",
    "print('> Number of Classes: {}'.format(len(set(dataset.target_names))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shape = [63, 63, 3]\n",
    "num_classes = len(set(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initalize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(sess=tf.Session(),\n",
    "              data_shape=data_shape,\n",
    "              num_classes=num_classes,\n",
    "              num_dense=num_dense,\n",
    "              learning_rate=learning_rate,\n",
    "              use_batch_norm=use_dropout,\n",
    "              use_dropout=use_dropout,\n",
    "              conv_parameters=conv2d_specifications,\n",
    "              max_pool_parameters=max_pool_specifications,\n",
    "              dropout_parameters=dropout_parameters,\n",
    "              fc_parameters=fc_parameters,\n",
    "              tensorboard_directory=tensorboard_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train_data(data=X_train,\n",
    "                 labels=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.val_data(data=X_val,\n",
    "               labels=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.test_data(data=X_test,\n",
    "                labels=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(batch_size=batch_size,\n",
    "            batch_size_val=batch_size,\n",
    "            epochs=1,\n",
    "            is_restore=restore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
